{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_address_input_1 = {\n",
    "    'Address': \"A 406, Siddhivinayak Apartment, S. V. Road, Opp. Police station, Malad (west), Mumbai 400064\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_address_input_2 = {'address_line_1': 'C-302, Oberoi Splendour apartment'\n",
    "                          , 'address_line_2': 'Jogeshwari Vikhroli Link Road, Andheri (E), Mumbai 400072'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_address_input_3 = {\n",
    "    'House': '1023, Rajesh Tower'\n",
    "    , 'Address': 'Mahavir Nagar, Borivali West'\n",
    "    , 'Landmark': 'near J B Kot School'\n",
    "    , 'City': 'Mumbai'\n",
    "    , 'State': 'Maharashtra'\n",
    "    , 'Pincode': 400092\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions\n",
    "1. It is assumed that we have data of only Indian addresses\n",
    "2. Addresses of other countries can have significant differences in the \n",
    "general format, hence they are not considered\n",
    "3. Only inputs of the forms shared in the assignment pdf are considered\n",
    "4. It is assumed that we have an existing database of addresses parsed in the \n",
    "format required as well as their raw formats\n",
    "5. Area is ignored for now as there is lack of clarity as to what it represents\n",
    "6. Only addresses of the 3 types are considered\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the problems we can face while processing addresses\n",
    "- Misspelled words\n",
    "- Missing space or extra spaces\n",
    "- Incorrect label\n",
    "- Abbreviation usage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain preprocessing steps can be done:\n",
    "- Common abbreviations used can be replaced with a standard name e.g. Street instead of st\n",
    "- All addresses can be converted to lowercase \n",
    "- Extra spaces can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_common_abbreviations(address: str) -> str:\n",
    "    abbreviations_dict = {\n",
    "    'Opp.': 'Opposite',\n",
    "    'opp.' : 'opposite',\n",
    "    'St': 'Street',\n",
    "    'Ave': 'Avenue',\n",
    "    'Blvd': 'Boulevard',\n",
    "    'Rd': 'Road',\n",
    "    'Dr': 'Drive',\n",
    "    'Ln': 'Lane',\n",
    "    'Cir': 'Circle',\n",
    "    'Ct': 'Court',\n",
    "    'Ter': 'Terrace',\n",
    "    'Pl': 'Place',\n",
    "    'Pkwy': 'Parkway',\n",
    "    'Way': 'Way',\n",
    "    'Hwy': 'Highway',\n",
    "}\n",
    "    words = address.split()\n",
    "    for i, word in enumerate(words):\n",
    "        if word in abbreviations_dict:\n",
    "            words[i] = abbreviations_dict[word]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_address_to_lowercase(address:str)->str:\n",
    "    return address.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(address:str)->str:\n",
    "    # using re module\n",
    "    return re.sub(r'\\s+', ' ', address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_addresses(address: str) -> str:\n",
    "    temp_address = handle_common_abbreviations(address)\n",
    "    temp_address = convert_address_to_lowercase(temp_address)\n",
    "    temp_address = remove_extra_spaces(temp_address)\n",
    "    return temp_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_house(address: str) -> str:\n",
    "    words = address.split(',')[0:2]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_locality(address: str) -> str:\n",
    "    words = address.split(',')[2]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landmark(address: str) -> str:\n",
    "    words = address.split(\",\")\n",
    "    keywords = ['near', 'opposite', 'behind', 'beside']\n",
    "    for index, word in enumerate(words):\n",
    "        for keyword in keywords:\n",
    "            if keyword in word:\n",
    "                required_segment = words[index]\n",
    "                return required_segment\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_city(address):\n",
    "    cities_data = pd.read_html('https://en.wikipedia.org/wiki/List_of_cities_in_India_by_population')[0]\n",
    "    cities = list(cities_data['City'].unique())\n",
    "    words = address.split(',')\n",
    "    for word in words:\n",
    "        if word in cities:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_state(address):\n",
    "    cities_data = pd.read_html('https://en.wikipedia.org/wiki/List_of_cities_in_India_by_population')[0]\n",
    "    states = list(cities_data['State'].unique())\n",
    "    words = address.split(',')\n",
    "    for word in words:\n",
    "        if word in states:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_address_of_single_entry_form(address):\n",
    "    address = preprocess_addresses(address)\n",
    "    house = extract_house(address)\n",
    "    locality = extract_locality(address) \n",
    "    landmark = extract_landmark(address)\n",
    "    city = extract_city(address)\n",
    "    state = extract_state(address)\n",
    "    postal_code = re.search(r\",\\s[A-Za-z\\s\\(\\)\\/]+[,]\\s[A-Za-z]+\\s([0-9]+)\", address).group(1)\n",
    "    country = 'India'\n",
    "    return house, locality, landmark, city, state, postal_code, country\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudocode for processing addresses of type 1\n",
    "- Apply the preprocessing steps as above\n",
    "- Get the components in processed format\n",
    "\n",
    "*Note: All functions will be applied in the form of an apply function through pandas*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudocode for processing addresses of type 2\n",
    "- Join the strings\n",
    "- Apply similar operations as done for addresses of type 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudocode for processing addresses of type 3\n",
    "- Directly fetch the data as its already processed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudocode for the whole processing flow\n",
    "- Apply the functions to a given dataset(lets assume its a pandas dataframe)\n",
    "- Columns will be added for each of the required fields using apply function of pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For taking care of misspelled cities for example, we could use the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_cities(misspelled_city, indian_cities_list):\n",
    "    closest_cities = difflib.get_close_matches(misspelled_city, indian_cities_list, n=1, cutoff=0.6)\n",
    "    corrected_city = closest_cities[0]\n",
    "    return corrected_city"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar functions as above can be used for other components as well"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have existing addresses , we could use them to do a fuzzy match as shown below. This will tackle most spelling related issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm 2\n",
    "# Using fuzzy matching\n",
    "from fuzzywuzzy import fuzz\n",
    "address_1 = {'240/A Dum Dum Park, Kolkata 700055'}\n",
    "address_2 = {'240 A dum dum park KOLkata 55'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_score = fuzz.token_set_ratio(address_1, address_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also use NLP related models or Google Map Geocoding APIs to solve the problems\n",
    "1. Geocoding API\n",
    "- Geocoding API can be used to designate addresses based on lat and long\n",
    "- This will make it easier to collapse multiple addresses together easily\n",
    "- This can also handle spelling related issues\n",
    "2. NLP\n",
    "-  One common approach to address component extraction is to use named entity recognition (NER). NER is a subtask of natural language processing that involves identifying and classifying entities, such as people, organizations, and locations, in text.\n",
    "- To extract address components, you would first train a NER model on a dataset of addresses. The dataset would need to include a variety of different address formats, as addresses can be written in many different ways. Once the model is trained, you can use it to identify and extract address components from new text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pincodes can also be used to get states or cities in some cases as they follow a designated format\n",
    "\n",
    "Ref:https://en.wikipedia.org/wiki/Postal_Index_Number#Postal_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General info\n",
    "# - A typical Indian pincode would consist of \n",
    "# 1. Zone(1st digit)\n",
    "# 2. Sub-zone(2nd digit)\n",
    "# 3. Sorting District (3rd digit)\n",
    "# 4. Post Office (Last 3 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues that can come up while processing\n",
    "\n",
    "- Missing locality\n",
    "- Missing city, state or zip code\n",
    "- Incorrect formatting\n",
    "- Unrecognized abbreviations\n",
    "- Typographical errors\n",
    "\n",
    "Possible solutions\n",
    "\n",
    "- Using lat or long instead\n",
    "- Using pincode to get state or city\n",
    "- Using existing/3rd party data sources to validate addresses\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "address",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c05c3d102aee71e5cbc17b33c91f202f01498c2fb0f29d790833cf9667822fd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
